{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "It is now time to generate some text from the models we trained!\n",
    "\n",
    "As a recap:\n",
    " - we trained a **first bidirectional LSTM model** to predict the next word of a given sequence of 30 words.\n",
    " - we train a **doc2vec model** for the whole input text as space, sentence based,\n",
    " - we trained a **second bidirectional LSTM model** to predict the best vectorized-sentence, following a sequence of 15 vectorized-phrases.\n",
    " \n",
    "So, what will be the process of our text generation ? We have first to provide a seed of 15 sentences, that contain at least 30 words. then:\n",
    " 1. using the last 30 words of the seed, we generate 10 candidates sentences.\n",
    " 2. we infer their vectors using the doc2vec model,\n",
    " 3. we calculate the \"best vector\" for the sentence following the 15 phrases of the seed,\n",
    " 4. we compare the infered vectors with the \"best vector\", and pick-up the closest one.\n",
    " 5. we add the generated sentence corresponding to this vector at the end of the seed, as the next sentence of the text.\n",
    " 6. then, we loop over the process.\n",
    " \n",
    "## 0. import libraries and parameters\n",
    "\n",
    "In order to start, we have to import our models and retrieve our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import double_log\n",
    "def print(*args, **kwargs):\n",
    "    return double_log.print(*args, **kwargs)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'save' # directory to store models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy, and french model\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading doc2Vec model...\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "#import gensim library\n",
    "import gensim\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "#load the doc2vec model\n",
    "print(\"loading doc2Vec model...\")\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('./data/doc2vec.w2v')\n",
    "\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary...\n",
      "vocabulary loaded !\n"
     ]
    }
   ],
   "source": [
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "\n",
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "\n",
    "vocab_size = len(words)\n",
    "print(\"vocabulary loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word prediction model...\n",
      "model loaded!\n",
      "loading sentence selection model...\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# load the keras models\n",
    "print(\"loading word prediction model...\")\n",
    "\n",
    "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')\n",
    "print(\"model loaded!\")\n",
    "print(\"loading sentence selection model...\")\n",
    "model_sequence = load_model(save_dir + \"/\" + 'my_model_sequence_lstm.final2.hdf5')\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Functions to generate Candidates Sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the text generation, and tune a bit the word prediction, we introduce a specific function to pick-up words from our vocabulary.\n",
    "\n",
    "We will not take the words with the highest prediction (or the generation of text will be boring), but would like to insert some uncertainties, and let the solution, sometime, to pick-up words with less good prediction.\n",
    "\n",
    "That is the purpose of the function **sample()**, that will draw randomly a word from our vocabulary.\n",
    "\n",
    "However, the probability for a word to be drawn will depends directly on its probability to be the next word, thanks to our first bidirectional LSTM Model.\n",
    "\n",
    "In order to tune this probability, we introduce a \"temperature\" to smooth or sharpen its value.\n",
    " - **if _temperature = 1.0_**, the probability for a word to be drawn is equal to the probability for the word to be the next one in the sequence (output of the owrd prediction model),\n",
    " - **if _temperature_ is big (much bigger than 1)**, the range of probabilities is shorten: the probabilities for all words to be the next one is closer to 1. More variety of words will be picked-up from the vocabulary.\n",
    " - **if _temperatune_ is small (close to 0)**, small probabilities will be avoided (they will be set closed to 0). Less words will be picked-up from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **create_seed()** function is usefull to prepare seed sequences, especially if the number of words in the seed phrase is lower than the espected number for a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seed(seed_sentences,nb_words_in_seq=20, verbose=False):\n",
    "    #initiate sentences\n",
    "    generated = ''\n",
    "    sentence = []\n",
    "    \n",
    "    #fill the sentence with a default word\n",
    "    for i in range (nb_words_in_seq):\n",
    "        sentence.append(\"and\")\n",
    "\n",
    "    seed = seed_sentences.split()\n",
    "    \n",
    "    if verbose == True : print(\"seed: \",seed)\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        sentence[nb_words_in_seq-i-1]=seed[len(seed)-i-1]\n",
    "        #print(i, sentence)\n",
    "\n",
    "    generated += ' '.join(sentence)\n",
    "    \n",
    "    if verbose == True : print('Generating text with the following seed: \"' + ' '.join(sentence) + '\"')\n",
    "\n",
    "    return [generated, sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function **generate_phrase()** is used to create the next phrase of a given sentence.\n",
    "\n",
    "It requires as inputs:\n",
    " - the previous sentence,\n",
    " - the maximum number of words in the phrase,\n",
    " - the temperature of the sample function.\n",
    " \n",
    "If a punctuation word is reached before the maximum number of the words, the function ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phrase(sentence, max_words = 50, nb_words_in_seq=20, temperature=1, verbose = False):\n",
    "    generated = \"\"\n",
    "    words_number = max_words - 1\n",
    "    ponctuation = [\".\",\"?\",\"!\",\":\",\"â€¦\"]\n",
    "    seq_length = nb_words_in_seq\n",
    "    #sentence = []\n",
    "    is_punct = False\n",
    "    #generate the text\n",
    "    for i in range(words_number):\n",
    "        #create the vector\n",
    "        x = np.zeros((1, seq_length, vocab_size))\n",
    "        for t, word in enumerate(sentence):\n",
    "            try:\n",
    "                x[0, nb_words_in_seq-len(sentence)+t, vocab[word]] = 1.\n",
    "            except:\n",
    "                print(t, word, vocab[word])\n",
    "                print(sentence)\n",
    "                return\n",
    "        #print(x.shape)\n",
    "\n",
    "        #calculate next word\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_word = vocabulary_inv[next_index]\n",
    "        \n",
    "        if verbose == True:\n",
    "            predv = np.array(preds)\n",
    "            #arr = np.array([1, 3, 2, 4, 5])\n",
    "            wi = predv.argsort()[-3:][::-1]\n",
    "            print(\"potential next words: \", vocabulary_inv[wi[0]], vocabulary_inv[wi[1]], vocabulary_inv[wi[2]])\n",
    "\n",
    "        #add the next word to the text\n",
    "        if is_punct == False:\n",
    "            if next_word in ponctuation:\n",
    "                is_punct = True\n",
    "            generated += \" \" + next_word\n",
    "            # shift the sentence by one, and and the next word at its end\n",
    "            sentence = sentence[1:] + [next_word]\n",
    "\n",
    "    return(generated, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function **define_phrases_candidates()** provides a list of potential phrases, for a given previous sentence and a specific temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_phrases_candidates(sentence, max_words = 50,\\\n",
    "                              nb_words_in_seq=20, \\\n",
    "                              temperature=1, \\\n",
    "                              nb_candidates_sents=10, \\\n",
    "                              verbose = False):\n",
    "    phrase_candidate = []\n",
    "    generated_sentence = \"\"\n",
    "    for i in range(nb_candidates_sents):\n",
    "        generated_sentence, new_sentence = generate_phrase(sentence, \\\n",
    "                                                           max_words = max_words, \\\n",
    "                                                           nb_words_in_seq = nb_words_in_seq, \\\n",
    "                                                           temperature=temperature, \\\n",
    "                                                           verbose = False)\n",
    "        phrase_candidate.append([generated_sentence, new_sentence])\n",
    "    \n",
    "    if verbose == True :\n",
    "        for phrase in phrase_candidate:\n",
    "            print(\"   \" , phrase[0])\n",
    "    return phrase_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions to select the best sentence\n",
    "\n",
    "the **create_sentences()** function generate a sequence of words (a list) for a given spacy doc item.\n",
    "\n",
    "It will be used to create a sequence of words from a single phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(doc):\n",
    "    ponctuation = [\".\",\"?\",\"!\",\":\",\"â€¦\"]\n",
    "    sentences = []\n",
    "    sent = []\n",
    "    for word in doc:\n",
    "        if word.text not in ponctuation:\n",
    "            if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "                sent.append(word.text.lower())\n",
    "        else:\n",
    "            sent.append(word.text.lower())\n",
    "            if len(sent) > 1:\n",
    "                sentences.append(sent)\n",
    "            sent=[]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the **generate_training_vector()** function is used to predict the next vectorized-sentence for a given sequence of vectorized-sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_vector(sentences_list, verbose = False):\n",
    "    if verbose == True : print(\"generate vectors for each sentence...\")\n",
    "    seq = []\n",
    "    V = []\n",
    "\n",
    "    for s in sentences_list:\n",
    "        #infer the vector of the sentence, from the doc2vec model\n",
    "        v = d2v_model.infer_vector(create_sentences(nlp(s))[0], alpha=0.001, min_alpha=0.001, steps=10000)\n",
    "    #create the vector array for the model\n",
    "        V.append(v)\n",
    "    V_val=np.array(V)\n",
    "    #expand dimension to fit the entry of the model : that's the training vector\n",
    "    V_val = np.expand_dims(V_val, axis=0)\n",
    "    if verbose == True : print(\"Vectors generated!\")\n",
    "    return V_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **select_next_phrase()** function allows us to pick-up the best candidates for the next phrase.\n",
    "\n",
    "First, it calculates the vector for each candidates.\n",
    "\n",
    "Then, based on the vector generated by the function **generate_training_vector()**, it performs a cosine similarity with them and pick the one with the biggest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_phrase(model, V_val, candidate_list, verbose=False):\n",
    "    sims_list = []\n",
    "    \n",
    "    #calculate prediction\n",
    "    preds = model.predict(V_val, verbose=0)[0]\n",
    "    \n",
    "    #calculate vector for each candidate\n",
    "    for candidate in candidate_list:\n",
    "        #calculate vector\n",
    "        #print(\"calculate vector for : \", candidate[1])\n",
    "        V = np.array(d2v_model.infer_vector(candidate[1]))\n",
    "        #calculate csonie similarity\n",
    "        sim = scipy.spatial.distance.cosine(V,preds)\n",
    "        #populate list of similarities\n",
    "        sims_list.append(sim)\n",
    "    \n",
    "    #select index of the biggest similarity\n",
    "    m = max(sims_list)\n",
    "    index_max = sims_list.index(m)\n",
    "    \n",
    "    if verbose == True :\n",
    "        print(\"selected phrase :\")\n",
    "        print(\"     \", candidate_list[index_max][0])\n",
    "    return candidate_list[index_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text generation - workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function, **generate_paragraph()**, combines all previous functions to generate the text.\n",
    "\n",
    "With the following parameters:\n",
    " - phrase_seed : the sentence seed for the first word prediction. It is a list of words.\n",
    " - sentences_seed : the seed sequence of sentences. It is a list of sentences.\n",
    " - max_words: the maximum number of words for a new generated sentence.\n",
    " - nb_words_in_seq: the number of words to keep as seed for the next word prediction.\n",
    " - temperature: the temperature for the word prediction.\n",
    " - nb_phrases: the number of phrase (sentence) to generate.\n",
    " - nb_candidates_sents: the number of phrase candidates to generate for each new phrase.\n",
    " - verbose: verbosity of the script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraphe(phrase_seed, sentences_seed, \\\n",
    "                        max_words = 50, \\\n",
    "                        nb_words_in_seq=20, \\\n",
    "                        temperature=1, \\\n",
    "                        nb_phrases=30, \\\n",
    "                        nb_candidates_sents=10, \\\n",
    "                        verbose=True):\n",
    "    \n",
    "    sentences_list = sentences_seed\n",
    "    sentence = phrase_seed   \n",
    "    text = []\n",
    "    \n",
    "    for p in range(nb_phrases):\n",
    "        if verbose == True : print(\"\")\n",
    "        if verbose == True : print(\"#############\")\n",
    "        print(\"phrase \",p+1, \"/\", nb_phrases)\n",
    "        if verbose == True : print(\"#############\")       \n",
    "        if verbose == True:\n",
    "            print('Sentence to generate phrase : ')\n",
    "            print(\"     \", sentence)\n",
    "            print(\"\")\n",
    "            print('List of sentences to constrain next phrase : ')\n",
    "            print(\"     \", sentences_list)\n",
    "            print(\"\")\n",
    "    \n",
    "        #generate seed training vector\n",
    "        V_val = generate_training_vector(sentences_list, verbose = verbose)\n",
    "\n",
    "        #generate phrase candidate\n",
    "        if verbose == True : print(\"generate phrases candidates...\")\n",
    "        phrases_candidates = define_phrases_candidates(sentence, \\\n",
    "                                                       max_words = max_words, \\\n",
    "                                                       nb_words_in_seq = nb_words_in_seq, \\\n",
    "                                                       temperature=temperature, \\\n",
    "                                                       nb_candidates_sents=nb_candidates_sents, \\\n",
    "                                                       verbose = verbose)\n",
    "        \n",
    "        if verbose == True : print(\"select next phrase...\")\n",
    "        next_phrase = select_next_phrase(model_sequence, \\\n",
    "                                         V_val,\n",
    "                                         phrases_candidates, \\\n",
    "                                         verbose=verbose)\n",
    "        \n",
    "        print(\"Next phrase: \",next_phrase[0])\n",
    "        if verbose == True :\n",
    "            print(\"\")\n",
    "            print(\"Shift phrases in sentences list...\")\n",
    "        for i in range(len(sentences_list)-1):\n",
    "            sentences_list[i]=sentences_list[i+1]\n",
    "\n",
    "        sentences_list[len(sentences_list)-1] = next_phrase[0]\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(\"done.\")\n",
    "            print(\"new list of sentences :\")\n",
    "            print(\"     \", sentences_list)     \n",
    "        sentence = next_phrase[1]\n",
    "        \n",
    "        text.append(next_phrase[0])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform the complete text generation workflow.\n",
    "\n",
    "First, we have to define the sentences in the seed (15 phrases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"he tapped meditatively on the table with his thin taper fingers like a man trying to recall a tune . \"\n",
    "s2 = '\"in other words a tree sticks in the mud from years end to years end,\" answered treherne . '\n",
    "s3 = \"you will have a cigar , mr. treherne ? \"\n",
    "s4 = \"it seems they have a way of eating things . \"\n",
    "s5 = \"squire vane stood up his silver hair flaming in the wind . \"\n",
    "s6 = \"She was silent a long time and said at last . \"\n",
    "s7 = \"i was born then or woke up or something . \"\n",
    "s8 = \"i would greatly appreciate if your brother died .\"\n",
    "s9 = \"there are powers there is the spirit of a place there are presences that are not to be put by . \"\n",
    "s10 = \"hey you can not do that by simply calling him .\"\n",
    "s11 = \"i hate tables because they are always with chairs .\"\n",
    "s12 = \"i had walked in this garden like a somnambulist in the sun . \"\n",
    "s13 = \"the french minister was arrested shortly after the meeting .\"\n",
    "s14 = \"by foreign affairs we do not mean killing .\"\n",
    "s15 = \"oh do not fancy i am sentimental and hanker after the good old days . \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:\n",
      "55576\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "file_list = ['G K Chesterton___The Trees of Pride.txt', 'Charles Dickens___The Chimes.txt']\n",
    "data_dir = \"./data/Gutenberg/txt\"\n",
    "num_words = 0\n",
    "for txt in file_list:\n",
    "    with open(data_dir+'/'+txt, 'r') as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            num_words += len(words)\n",
    "print(\"Number of words:\")\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine them in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'he tapped meditatively on the table with his thin taper fingers like a man trying to recall a tune . ', u'\"in other words a tree sticks in the mud from years end to years end,\" answered treherne . ', u'you will have a cigar , mr. treherne ? ', u'it seems they have a way of eating things . ', u'squire vane stood up his silver hair flaming in the wind . ', u'She was silent a long time and said at last . ', u'i was born then or woke up or something . ', u'i would greatly appreciate if your brother died .', u'there are powers there is the spirit of a place there are presences that are not to be put by . ', u'hey you can not do that by simply calling him .', u'i hate tables because they are always with chairs .', u'i had walked in this garden like a somnambulist in the sun . ', u'the french minister was arrested shortly after the meeting .', u'by foreign affairs we do not mean killing .', u'oh do not fancy i am sentimental and hanker after the good old days . ']\n"
     ]
    }
   ],
   "source": [
    "sentences_list = []\n",
    "for i in [s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15]:\n",
    "    sentences_list.append(unicode(i, 'utf-8'))\n",
    "print(sentences_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate them in a single phrase and create the seed sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do not mean killing . oh do not fancy i am sentimental and hanker after the good old days .\n",
      "['do', 'not', 'mean', 'killing', '.', 'oh', 'do', 'not', 'fancy', 'i', 'am', 'sentimental', 'and', 'hanker', 'after', 'the', 'good', 'old', 'days', '.']\n",
      "[u'do', u'not', u'mean', u'killing', u'.', u'oh', u'do', u'not', u'fancy', u'i', u'am', u'sentimental', u'and', u'hanker', u'after', u'the', u'good', u'old', u'days', u'.']\n"
     ]
    }
   ],
   "source": [
    "phrase_seed, sentences_seed_one = create_seed(s1 + \" \" + s2 + \" \" +\\\n",
    "                                          s3 + \" \" + s4+ \" \" + s5 + \" \" +\\\n",
    "                                          s6 + \" \" + s7 + \" \" + s8 + \" \" +\\\n",
    "                                          s9+ \" \" + s10 + \" \" + s11 + \" \" +\\\n",
    "                                          s12 + \" \" + s13 + \" \" + s14+ \" \" + s15,20)\n",
    "print(phrase_seed)\n",
    "print(sentences_seed_one)\n",
    "sentences_seed = []\n",
    "for i in sentences_seed_one:\n",
    "    sentences_seed.append(unicode(i, \"utf-8\"))\n",
    "print(sentences_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'he', u'tapped', u'meditatively', u'on', u'the', u'table', u'with', u'his', u'thin', u'taper', u'fingers', u'like', u'a', u'man', u'trying', u'to', u'recall', u'a', u'tune', u'.']]\n",
      "[[u'\"', u'in', u'other', u'words', u'a', u'tree', u'sticks', u'in', u'the', u'mud', u'from', u'years', u'end', u'to', u'years', u'end', u',', u'\"', u'answered', u'treherne', u'.']]\n",
      "[[u'you', u'will', u'have', u'a', u'cigar', u',', u'mr', u'.'], [u'treherne', u'?']]\n",
      "[[u'it', u'seems', u'they', u'have', u'a', u'way', u'of', u'eating', u'things', u'.']]\n",
      "[[u'squire', u'vane', u'stood', u'up', u'his', u'silver', u'hair', u'flaming', u'in', u'the', u'wind', u'.']]\n",
      "[[u'she', u'was', u'silent', u'a', u'long', u'time', u'and', u'said', u'at', u'last', u'.']]\n",
      "[[u'i', u'was', u'born', u'then', u'or', u'woke', u'up', u'or', u'something', u'.']]\n",
      "[[u'i', u'would', u'greatly', u'appreciate', u'if', u'your', u'brother', u'died', u'.']]\n",
      "[[u'there', u'are', u'powers', u'there', u'is', u'the', u'spirit', u'of', u'a', u'place', u'there', u'are', u'presences', u'that', u'are', u'not', u'to', u'be', u'put', u'by', u'.']]\n",
      "[[u'hey', u'you', u'can', u'not', u'do', u'that', u'by', u'simply', u'calling', u'him', u'.']]\n",
      "[[u'i', u'hate', u'tables', u'because', u'they', u'are', u'always', u'with', u'chairs', u'.']]\n",
      "[[u'i', u'had', u'walked', u'in', u'this', u'garden', u'like', u'a', u'somnambulist', u'in', u'the', u'sun', u'.']]\n",
      "[[u'the', u'french', u'minister', u'was', u'arrested', u'shortly', u'after', u'the', u'meeting', u'.']]\n",
      "[[u'by', u'foreign', u'affairs', u'we', u'do', u'not', u'mean', u'killing', u'.']]\n",
      "[[u'oh', u'do', u'not', u'fancy', u'i', u'am', u'sentimental', u'and', u'hanker', u'after', u'the', u'good', u'old', u'days', u'.']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/ipykernel_launcher.py:6: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n",
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/ipykernel_launcher.py:7: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for s in sentences_list:\n",
    "    #print(s)\n",
    "    print(create_sentences(nlp(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script to generate the text !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase  1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/ipykernel_launcher.py:6: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n",
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/ipykernel_launcher.py:7: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  import sys\n",
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/ipykernel_launcher.py:34: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next phrase:   \n",
      " i am , or , i am a of the little to be \n",
      " ; and , and the and \n",
      " of the things , , and a old man , \n",
      " was a man , and a more of , and the of the \n",
      " - which had been a made a .\n",
      "phrase  2 / 5\n",
      "Next phrase:   he was \n",
      " a .\n",
      "phrase  3 / 5\n",
      "Next phrase:   if you were a heart .\n",
      "phrase  4 / 5\n",
      "Next phrase:     i have been \n",
      " a hand a times .\n",
      "phrase  5 / 5\n",
      "Next phrase:     , and a hands â€” .\n"
     ]
    }
   ],
   "source": [
    "text = generate_paragraphe(sentences_seed, sentences_list, \\\n",
    "                           max_words = 80, \\\n",
    "                           nb_words_in_seq = 30,\\\n",
    "                           temperature=0.201, \\\n",
    "                           nb_phrases=5, \\\n",
    "                           nb_candidates_sents=7, \\\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the new text generated is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text: \n",
      " \r\n",
      " i am , or , i am a of the little to be \r\n",
      " ; and , and the and \r\n",
      " of the things , , and a old man , \r\n",
      " was a man , and a more of , and the of the \r\n",
      " - which had been a made a .\n",
      " he was \r\n",
      " a .\n",
      " if you were a heart .\n",
      "   i have been \r\n",
      " a hand a times .\n",
      "   , and a hands â€” .\n"
     ]
    }
   ],
   "source": [
    "print(\"generated text: \")\n",
    "for t in text:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
